# -*- coding: UTF-8 -*-.
import argparse
import os
import csv
import numpy as np
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.svm import SVC
import re
import math
import random

N_GOODWARES = 100
N_MALWARES = 1000
TEST_SIZE = 0.1
FEATURES = [ "BaseOfCode", "BaseOfData", "Characteristics",
             "DllCharacteristics", "Entropy", "FileAlignment", "FileType", "FormatedTimeDateSteamp", "Fuzzy", "Identify", "ImageBase", "ImportedDlls", "ImportedSymbols", "MD5", "Machine", "Magic", "Name", "NumberOfRvaAndSizes", "NumberOfSections", "NumberOfSymbols", "PE_TYPE", "PointerToSymbolTable", "SHA1", "Size", "SizeOfCode", "SizeOfHeaders", "SizeOfImage", "SizeOfInitializedData", "SizeOfOptionalHeader", "SizeOfUninitializedData", "TimeDateStamp"]

USED_FEATURES = [ "BaseOfCode", "BaseOfData", "Characteristics",
                  "DllCharacteristics", "Entropy", "FileAlignment", "ImageBase", "Machine", "Magic", "NumberOfRvaAndSizes", "NumberOfSections", "NumberOfSymbols", "PE_TYPE", "PointerToSymbolTable", "Size", "SizeOfCode", "SizeOfHeaders", "SizeOfImage", "SizeOfInitializedData", "SizeOfOptionalHeader", "SizeOfUninitializedData", "TimeDateStamp"]

def params():
    parser = argparse.ArgumentParser()
    parser.add_argument('goodwares_csv', help='Goodwares CSV location')
    parser.add_argument('malwares_csv', help='Malwares CSV Location')
    params = parser.parse_args()
    return params.goodwares_csv, params.malwares_csv

def clear_text(text):
    text = text.replace("'","").replace("[","").replace("]","")
    text = re.sub("[^A-Za-z0-9]+","", text)
    return text.lower()

def read_file(input_file):
    with open(input_file, 'rb') as file:
        reader = csv.DictReader(file)
        features = []
        identifiers = []
        imported_dlls = []
        imported_symbols = []
        for row in reader:
            example = []
            for f in USED_FEATURES:
                example.append(row[f])
            # get compiler and packer info
            id_regex = r"\[\'[^']*\'\]"
            ident = re.findall(id_regex,row["Identify"])
            identify = ""
            for i in ident:
                identify += clear_text(i) + " "
            # get imported dlls
            dll_regex = r"\'[^']*\'"
            i_dlls = re.findall(dll_regex,row["ImportedDlls"])
            dlls = ""
            for d in i_dlls:
                dlls += clear_text(d) + " "
            # get imported symbols
            i_symbols = re.findall(dll_regex,row["ImportedSymbols"])
            symbols = ""
            for d in i_symbols:
                symbols += clear_text(d) + " "
            # apped texts to their arrays
            identifiers.append(identify)
            imported_dlls.append(dlls)
            imported_symbols.append(symbols)
            # append current example features
            features.append(example)
    features = np.array(features)
    identifiers = np.array(identifiers)
    imported_dlls = np.array(imported_dlls)
    imported_symbols = np.array(imported_symbols)
    return features, identifiers, imported_dlls, imported_symbols

def cross_validation(features, identifiers, dlls, symbols, labels, test_size):
    # total data
    n_data = len(features)
    # number of test data
    n_test = math.ceil(n_data*test_size)
    # get random n_test indexes
    indexes = random.sample(range(n_data), int(n_test))
    features_test = []
    features_train = []
    identifiers_test = []
    identifiers_train = []
    dlls_test = []
    dlls_train = []
    symbols_test = []
    symbols_train = []
    labels_test = []
    labels_train = []
    for i in range(len(features)):
        if i not in indexes:
            # add data i to train
            features_train.append(features[i])
            identifiers_train.append(identifiers[i])
            dlls_train.append(dlls[i])
            symbols_train.append(symbols[i])
            labels_train.append(labels[i])
        else:
            # add data i to test
            features_test.append(features[i])
            identifiers_test.append(identifiers[i])
            dlls_test.append(dlls[i])
            symbols_test.append(symbols[i])
            labels_test.append(labels[i])
    return features_train, features_test, identifiers_train, identifiers_test, dlls_train, dlls_test, symbols_train, symbols_test, labels_train, labels_test


# get params
gw_csv, mw_csv = params()

# read goodwares and malwares
gw_features, gw_identifiers, gw_dlls, gw_symbols = read_file(gw_csv)
mw_features, mw_identifiers, mw_dlls, mw_symbols = read_file(mw_csv)

print "Goodwares:",len(gw_features)
print "Malwares:", len(mw_features)

# create label arrays
gw_label = np.zeros(len(gw_features))
mw_label = np.ones(len(mw_features))

# cross validation
gw_features_train, gw_features_test, gw_identifiers_train, gw_identifiers_test, gw_dlls_train, gw_dlls_test, gw_symbols_train, gw_dlls_test, gw_labels_train, gw_labels_test = cross_validation(gw_features, gw_identifiers, gw_dlls, gw_symbols, gw_label,test_size=TEST_SIZE)

mw_features_train, mw_features_test, mw_identifiers_train, mw_identifiers_test, mw_dlls_train, mw_dlls_test, mw_symbols_train, mw_dlls_test, mw_labels_train, mw_labels_test = cross_validation(mw_features, mw_identifiers, mw_dlls, mw_symbols, mw_label,test_size=TEST_SIZE)

# create train and test sets
features_train = np.concatenate((gw_features_train, mw_features_train),axis=0)
labels_train = np.concatenate((gw_labels_train, mw_labels_train),axis=0)
features_test = np.concatenate((gw_features_test, mw_features_test),axis=0)
labels_test = np.concatenate((gw_labels_test, mw_labels_test),axis=0)

# use in a classifier
clf = SVC()
clf.fit(features_train, labels_train)
pred = clf.predict(features_test)
print accuracy_score(labels_test, pred)
print confusion_matrix(labels_test, pred)
